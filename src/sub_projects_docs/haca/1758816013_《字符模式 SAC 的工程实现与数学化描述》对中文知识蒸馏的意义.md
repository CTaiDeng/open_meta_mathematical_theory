# 《字符模式 SAC 的工程实现与数学化描述》对中文知识蒸馏的意义

- 作者：GaoZheng
- 日期：2025-09-26
- 版本：v1.0.0

## 摘要
本文围绕：首先明确问题背景与约束，给出可验证的形式化定义与工程接口；随后分解系统/模型/数据/指标的关键设计，并给出可复现的实现与对齐路径；最后总结风险与边界条件，给出落地建议与扩展路线。

---

本文从知识蒸馏（Knowledge Distillation, KD）的角度，刻画字符模式 SAC 中“中文词法先验”的注入方式与学习机理。通过词表并集 $\mathcal{C}$ 与长度集合 $U$ 构造“可变长度的前缀/后缀命中”信号，结合软目标分布与后验正则，实现从词级教师到字符级学生的结构化蒸馏，提升样本效率、对齐质量与可解释性。

---

## 1 教师先验与学生策略
- 词表并集（教师先验）
  $$\mathcal{C} = \texttt{chinese\_name\_frequency\_word.json} \,\cup\, \texttt{chinese\_frequency\_word.json}.$$
- 可变长度集合（来自真实语料）
  $$U = \text{union.lengths} \subset \mathbb{N}, \quad \text{from } \texttt{data/word\_length\_sets.json}.$$
- 字符模式观测关键量：目标字符 $\chi_t$、预览 $\mathrm{prev}_t$、源串 $\mathrm{source}_t = \mathrm{prev}_t \oplus \chi_t$。

以 $\mathcal{C}, U$ 为“教师先验”，在字符粒度下注入词级边界信息，缓解字/词粒度鸿沟。

## 2 软目标（Soft Targets）构造
- 质量软信号与命中奖励：
  $$\chi_t^{\mathrm{soft}} = \max(0, Q_t + L_t), \qquad
    \delta_t = \begin{cases}
    1, & \exists L\in U,\ \mathrm{tail}(s_t,L)\in \mathcal{C},\\
    0.5, & \mathrm{tail}(s_t,1)=\text{target\_char},\\
    0, & \text{otherwise}.
  \end{cases}$$
- 基于词法命中的“教师分布” $q_t$（首步动作的软标签）：
  $$q_t(a) \propto \beta \sum_{L\in U} w_L\, \mathbf{1}\{\mathrm{tail}(\chi_t \oplus a, L) \in \mathcal{C}\}
  + (1-\beta)\, \mathbf{1}\{a_1 = \text{target\_char}\},$$
  其中 $a_1$ 为 $a$ 的首字，$\beta\in[0,1]$ 权衡词法/逐字信号，$w_L\ge 0$ 为长度权重（可按频次或可信度设定）。

## 3 蒸馏损失与温度控制
- 带温度 $T$ 平滑的策略分布（首步）：$\pi_\theta(\cdot\mid x_t;T)$。
- 蒸馏损失：
  $$\mathcal{L}_{\mathrm{KD}} = \lambda_{\mathrm{kd}}\, \mathrm{KL}\bigl(q_t\,\Vert\,\pi_\theta(\cdot\mid x_t;T)\bigr).$$
- 与 SAC 联合优化：
  $$\min_\theta\; \mathcal{L}_{\mathrm{SAC}}(\theta) + \mathcal{L}_{\mathrm{KD}}(\theta).$$
其中 SAC 的熵温度 $\alpha$ 与采样 Top-$p$ 共同起到“平滑/防过拟合”的作用，促进吸收近义候选的软概率质量。

## 4 对齐蒸馏：前缀左扩与后缀命中
- 前缀对齐目标（历史左扩后）：
  $$\exists L\in U\cap[1..|\mathrm{source}_t|],\quad \mathrm{prefix}(\mathrm{source}_t,L)\in\mathcal{C}.$$
- 作为后验正则：
  $$c_{\mathrm{prefix}}(x) = \mathbf{1}\{\neg\exists L\in U:\mathrm{prefix}(\mathrm{source},L)\in\mathcal{C}\},\qquad
    \mathcal{L}_{\mathrm{PR}} = \lambda_{\mathrm{pr}}\, \mathbb{E}_{\pi_\theta}[c_{\mathrm{prefix}}(x_t)].$$
- 后缀对齐（raw\_action 与 bigram 共用 $U$）：
  $$\exists L\in U\cap[1..|q|],\; \mathrm{tail}(q,L)\in\mathcal{C}\quad \text{或}\quad \exists L\in U\cap[1..|s|],\; \mathrm{tail}(s,L)\in\mathcal{C}.$$

## 5 多教师融合（Mixture-of-Teachers）
两张词表可视作两个教师 $q_t^{(1)}, q_t^{(2)}$，其凸组合：
$$q_t = \pi_1 q_t^{(1)} + \pi_2 q_t^{(2)},\qquad \pi_1,\pi_2\ge 0,\; \pi_1+\pi_2=1,$$
权重可由词频、编号可信度或领域匹配度决定，兼顾通用词与专名词。

## 6 奖励塑形与样本效率
以势能塑形思想增广奖励：
$$r'_t = r_t + \eta\,\delta_t + \mu\,\chi_t^{\mathrm{soft}},$$
其中 $\eta,\mu\ge 0$。该塑形缩短信号回传路径，缓解仅终端质量分的稀疏问题，提高样本效率与收敛稳定性。

## 7 长度集合 $U$ 的蒸馏作用
在独立近似下，命中概率上界估计：
$$\Pr[\text{hit}] \approx 1 - \prod_{L\in U} (1 - p_L),\qquad p_L = \Pr\bigl(\mathrm{tail}(\cdot,L)\in\mathcal{C}\bigr).$$
相较固定二字（$U=\{2\}$），经验并集 $U$ 提升了多字词的边界对齐概率，增强 OOV 与长词边界的鲁棒性与可解释性。

## 8 评测指标（蒸馏视角）
- 前缀/后缀命中率：
  $$H_{\mathrm{prefix}}=\Pr\bigl(\exists L\in U:\mathrm{prefix}(\mathrm{source},L)\in\mathcal{C}\bigr),\quad
    H_{\mathrm{suffix}}=\Pr\bigl(\exists L\in U:\mathrm{tail}(s,L)\in\mathcal{C}\bigr).$$
- 平均命中长度与 OOV 一致性：
  $$\bar L_{\mathrm{hit}}=\mathbb{E}[L\mid \text{hit}],\qquad \mathrm{OOV@hit}=\Pr(\text{hit}\mid \text{OOV}).$$
- 蒸馏一致性（分布层面）：
  $$D_{\mathrm{KD}}=\mathbb{E}_t\bigl[\mathrm{KL}\bigl(q_t\,\Vert\,\pi_\theta(\cdot\mid x_t)\bigr)\bigr].$$

## 9 实践意义与落地
- 在字符粒度下注入词级边界与长度分布先验（$\mathcal{C}, U$），实现从词法教师到字符学生的结构化蒸馏。
- 与 SAC 的熵正则（$\alpha$）与 Top-$p$ 采样互补，兼顾探索与可控生成。
- 易扩展至领域词表、多教师/多视角蒸馏与自适应 $U$（早期偏短、后期扩长），在摘要/抽取/标题生成等中文场景提升对齐质量与可解释性。

---

**许可声明 (License)**

Copyright (C) 2025 GaoZheng

本文档采用[知识共享-署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0)](https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh-Hans)进行许可。
